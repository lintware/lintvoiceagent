<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LintVoice - Futuristic Voice</title>
    <script src="https://cdn.socket.io/4.5.4/socket.io.min.js"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <style>
        /* CSS Variables & Reset */
        :root {
            --bg-color: #ffffff;
            --text-main: #111111;
            --text-secondary: #666666;
            --accent-color: #000000;
            --bubble-user: #111111;
            --bubble-ai: #f3f3f3;
            --shadow-soft: 0 10px 30px rgba(0,0,0,0.05);
            --font-main: 'Inter', sans-serif;
        }

        * { box-sizing: border-box; margin: 0; padding: 0; }
        body {
            font-family: var(--font-main);
            background-color: var(--bg-color);
            color: var(--text-main);
            height: 100vh;
            display: flex;
            flex-direction: column;
            overflow: hidden;
        }

        /* Header */
        header {
            padding: 2rem 3rem;
            display: flex;
            justify-content: space-between;
            align-items: center;
            z-index: 10;
        }
        .logo {
            font-weight: 600;
            font-size: 1.5rem;
            letter-spacing: -0.05em;
        }
        .logo span { color: var(--text-secondary); }

        /* Main Container */
        main {
            flex: 1;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            position: relative;
            width: 100%;
            max-width: 800px;
            margin: 0 auto;
            padding: 2rem;
        }

        /* Chat Area */
        #chat-container {
            width: 100%;
            flex: 1;
            overflow-y: auto;
            padding: 2rem;
            display: flex;
            flex-direction: column;
            gap: 1.5rem;
            margin-bottom: 2rem;
            /* Hide scrollbar */
            scrollbar-width: none;
            -ms-overflow-style: none;
        }
        #chat-container::-webkit-scrollbar { display: none; }

        .message {
            max-width: 80%;
            padding: 1rem 1.5rem;
            border-radius: 1.5rem;
            font-size: 1rem;
            line-height: 1.5;
            opacity: 0;
            transform: translateY(20px);
            animation: fadeInUp 0.4s forwards;
        }

        .message.user {
            align-self: flex-end;
            background-color: var(--bubble-user);
            color: white;
            border-bottom-right-radius: 0.25rem;
        }

        .message.assistant {
            align-self: flex-start;
            background-color: var(--bubble-ai);
            color: var(--text-main);
            border-bottom-left-radius: 0.25rem;
        }

        /* Voice Interface */
        .voice-controls {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 1.5rem;
            margin-bottom: 4rem;
        }

        .mic-button {
            width: 80px;
            height: 80px;
            border-radius: 50%;
            background: var(--bg-color);
            border: 2px solid var(--accent-color);
            color: var(--accent-color);
            font-size: 1.5rem;
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            justify-content: center;
            box-shadow: var(--shadow-soft);
            position: relative;
            overflow: visible;
        }

        .mic-button:hover {
            transform: scale(1.05);
            background: var(--accent-color);
            color: white;
        }

        .mic-button.listening {
            background: var(--accent-color);
            color: white;
            animation: pulse 1.5s infinite;
        }

        .mic-button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .status-text {
            font-size: 0.875rem;
            color: var(--text-secondary);
            height: 1.2em;
            font-weight: 300;
        }

        /* Footer Links */
        .footer-links {
            position: absolute;
            bottom: 2rem;
            right: 3rem;
            display: flex;
            gap: 1.5rem;
            align-items: center;
        }

        .footer-link {
            color: var(--text-main);
            font-size: 1.5rem;
            cursor: pointer;
            transition: opacity 0.3s;
            opacity: 0.7;
            text-decoration: none;
        }
        .footer-link:hover { opacity: 1; }

        .lintware-link {
            font-size: 0.9rem;
            font-weight: 600;
            letter-spacing: -0.02em;
        }

        /* Animations */
        @keyframes fadeInUp {
            to { opacity: 1; transform: translateY(0); }
        }

        @keyframes pulse {
            0% { box-shadow: 0 0 0 0 rgba(0, 0, 0, 0.4); }
            70% { box-shadow: 0 0 0 20px rgba(0, 0, 0, 0); }
            100% { box-shadow: 0 0 0 0 rgba(0, 0, 0, 0); }
        }

        /* Toast */
        .toast {
            position: fixed;
            top: 2rem;
            left: 50%;
            transform: translateX(-50%) translateY(-100px);
            background: var(--accent-color);
            color: white;
            padding: 0.75rem 1.5rem;
            border-radius: 2rem;
            font-size: 0.875rem;
            transition: transform 0.3s cubic-bezier(0.175, 0.885, 0.32, 1.275);
            z-index: 100;
        }
        .toast.show {
            transform: translateX(-50%) translateY(0);
        }

        /* Error styling */
        .error {
            background: #ffe0e0;
            color: #d32f2f;
            padding: 0.75rem 1.5rem;
            border-radius: 2rem;
            font-size: 0.875rem;
            position: fixed;
            top: 2rem;
            left: 50%;
            transform: translateX(-50%) translateY(-100px);
            z-index: 100;
            border: 1px solid #ffcdd2;
            transition: transform 0.3s cubic-bezier(0.175, 0.885, 0.32, 1.275);
        }
        .error.active {
            transform: translateX(-50%) translateY(0);
        }

        /* Empty state */
        .empty-state {
            text-align: center;
            color: var(--text-secondary);
            padding: 2rem;
            font-size: 0.875rem;
        }
    </style>
</head>
<body>

    <header>
        <div class="logo">Lint<span>Voice</span></div>
    </header>

    <main>
        <div id="chat-container">
            <div class="empty-state">Tap to speak</div>
        </div>

        <div class="voice-controls">
            <div class="status-text" id="status-text">Ready</div>
            <button class="mic-button" id="mic-btn" disabled>
                <i class="fa-solid fa-microphone"></i>
            </button>
        </div>
    </main>

    <div class="footer-links">
        <a href="https://lintware.com" target="_blank" class="footer-link lintware-link">
            lintware
        </a>
        <div class="footer-link" id="github-btn">
            <i class="fa-brands fa-github"></i>
        </div>
    </div>

    <div class="toast" id="toast">Coming soon</div>
    <div class="error" id="error"></div>

    <script>
        let socket;
        let audioContext;
        let stream;
        let isRecording = false;
        // VAD is fixed to Silero

        const micBtn = document.getElementById('mic-btn');
        const chatContainer = document.getElementById('chat-container');
        const statusText = document.getElementById('status-text');
        const errorDiv = document.getElementById('error');
        const githubBtn = document.getElementById('github-btn');
        const toast = document.getElementById('toast');
        // No VAD toggle in this version

        // Audio playback queue for streaming TTS
        let audioQueue = [];
        let isPlayingAudio = false;
        let audioPlaybackContext = null;
        let currentSource = null;
        let playbackEnabled = true; // gate to ignore audio when stopped
        // Gapless scheduling state
        let nextStartTime = 0; // when the next chunk should start
        let activeSources = []; // all scheduled sources for cancel/stop

        socket = io();

        socket.on('connect', () => {
            micBtn.disabled = false;
            statusText.textContent = 'Ready';
            // Silero is default; no mode selection needed
        });

        socket.on('disconnect', () => {
            micBtn.disabled = true;
            statusText.textContent = 'Disconnected';
            // Ensure any ongoing audio is stopped on disconnect
            playbackEnabled = false;
            stopAudioPlayback();
        });

        socket.on('vad_mode_changed', (data) => {
            console.log('VAD:', data.message);
        });
        socket.on('stream_started', (data) => {
            console.log('Stream started');
        });

        let currentAssistantBubble = null;
        let currentPartialBubble = null;

        // Pipeline stage logging
        socket.on('pipeline_stage', (data) => {
            console.log(`%c[${data.stage.toUpperCase()}] ${data.message}`,
                'color: #007aff; font-weight: bold');
        });

        socket.on('partial_transcription', (data) => {
            console.log('[PARTIAL TRANSCRIPTION]', data.text);
            // Show partial transcription while user is speaking
            if (data.text) {
                if (!currentPartialBubble) {
                    // Create a partial message bubble (lighter style)
                    const emptyState = chatContainer.querySelector('.empty-state');
                    if (emptyState) {
                        emptyState.remove();
                    }

                    const messageDiv = document.createElement('div');
                    messageDiv.className = 'message user';
                    messageDiv.style.opacity = '0.6';  // Make it lighter

                    messageDiv.textContent = data.text;

                    chatContainer.appendChild(messageDiv);
                    chatContainer.scrollTop = chatContainer.scrollHeight;

                    currentPartialBubble = { div: messageDiv };
                } else {
                    // Update existing partial bubble
                    currentPartialBubble.div.textContent = data.text;
                    chatContainer.scrollTop = chatContainer.scrollHeight;
                }
            }
        });

        socket.on('user_message', (data) => {
            console.log('[USER MESSAGE] Displaying final transcription:', data.text);
            if (data.text) {
                // Remove partial bubble if exists
                if (currentPartialBubble) {
                    currentPartialBubble.div.remove();
                    currentPartialBubble = null;
                }
                // Add final message
                addMessage(data.text, 'user');
            }
        });

        socket.on('assistant_start', () => {
            console.log('[ASSISTANT START] Creating assistant message bubble');
            playbackEnabled = true;
            // Reset scheduling for a fresh response
            nextStartTime = 0;

            // Create empty assistant message bubble
            const emptyState = chatContainer.querySelector('.empty-state');
            if (emptyState) {
                emptyState.remove();
            }

            // Stop any ongoing audio from previous response
            stopAudioPlayback();

            const messageDiv = document.createElement('div');
            messageDiv.className = 'message assistant';
            messageDiv.textContent = '';

            chatContainer.appendChild(messageDiv);
            chatContainer.scrollTop = chatContainer.scrollHeight;

            currentAssistantBubble = messageDiv;
        });

        socket.on('assistant_token', (data) => {
            if (currentAssistantBubble && data.token) {
                // Log first few tokens
                if (currentAssistantBubble.textContent.length < 20) {
                    console.log('[ASSISTANT TOKEN] Received token:', data.token);
                }
                currentAssistantBubble.textContent += data.token;
                chatContainer.scrollTop = chatContainer.scrollHeight;
            }
        });

        // Periodic full text sync to fix any token drops
        socket.on('assistant_progress', (data) => {
            if (currentAssistantBubble && typeof data.text === 'string') {
                currentAssistantBubble.textContent = data.text;
                chatContainer.scrollTop = chatContainer.scrollHeight;
            }
        });

        socket.on('assistant_complete', (data) => {
            console.log('[ASSISTANT COMPLETE] Full response received');
            currentAssistantBubble = null;
        });

        // Handle streaming audio from TTS
        socket.on('assistant_audio', (data) => {
            console.log('[ASSISTANT AUDIO] Received audio chunk, queuing for playback');
            if (data.audio && playbackEnabled) {
                queueAudio(data.audio, data.sample_rate || 24000);
            }
        });

        // Cancel/stop assistant playback (barge-in)
        socket.on('assistant_cancel', () => {
            console.log('[ASSISTANT CANCEL] Stopping audio playback due to barge-in');
            playbackEnabled = false;
            stopAudioPlayback();
        });

        async function queueAudio(base64Audio, sampleRate) {
            // Decode base64 to ArrayBuffer
            const binaryString = atob(base64Audio);
            const bytes = new Uint8Array(binaryString.length);
            for (let i = 0; i < binaryString.length; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }

            // Add to queue
            audioQueue.push({ data: bytes.buffer, sampleRate: sampleRate });

            // Start playback if not already playing
            if (!isPlayingAudio) {
                playNextAudio();
            }
        }

        async function playNextAudio() {
            // Schedule all available chunks back-to-back for gapless playback
            if (audioQueue.length === 0) {
                isPlayingAudio = false;
                console.log('[AUDIO PLAYBACK] Queue empty, playback complete');
                return;
            }

            isPlayingAudio = true;

            // Initialize audio context if needed
            if (!audioPlaybackContext) {
                audioPlaybackContext = new (window.AudioContext || window.webkitAudioContext)();
                console.log('[AUDIO PLAYBACK] Audio context initialized');
                nextStartTime = 0; // reset scheduling baseline
            }

            try {
                // Schedule as many as are currently queued
                while (audioQueue.length > 0 && playbackEnabled) {
                    const audioData = audioQueue.shift();
                    // Decode WAV
                    const audioBuffer = await audioPlaybackContext.decodeAudioData(audioData.data);
                    console.log(`[AUDIO PLAYBACK] Decoded chunk: ${audioBuffer.duration.toFixed(2)}s`);

                    // Create and schedule source at precise time for gapless playback
                    const source = audioPlaybackContext.createBufferSource();
                    source.buffer = audioBuffer;
                    source.connect(audioPlaybackContext.destination);

                    // Compute start time: schedule after previously scheduled audio
                    const now = audioPlaybackContext.currentTime;
                    if (nextStartTime === 0 || nextStartTime < now) {
                        // Align to now with a tiny safety offset
                        nextStartTime = now + 0.02;
                    }
                    source.start(nextStartTime);
                    activeSources.push(source);
                    currentSource = source; // keep a reference to the most recent

                    // Advance next start time by duration
                    nextStartTime += audioBuffer.duration;
                }
            } catch (error) {
                console.error('[AUDIO PLAYBACK ERROR]', error);
            } finally {
                // If more audio arrives later, queueAudio() will call playNextAudio() again
                if (audioQueue.length === 0) {
                    isPlayingAudio = false;
                }
            }
        }

        function stopAudioPlayback() {
            // Stop all scheduled/playing sources
            try {
                activeSources.forEach(src => {
                    try {
                        src.stop(0);
                        src.disconnect();
                    } catch (_) {}
                });
                activeSources = [];
                if (currentSource) {
                    try { currentSource.stop(0); currentSource.disconnect(); } catch (_) {}
                    currentSource = null;
                }
            } catch (e) {
                console.warn('[AUDIO STOP WARNING]', e);
            }
            // Clear queue and reset scheduling
            audioQueue = [];
            isPlayingAudio = false;
            nextStartTime = 0;
        }

        socket.on('error', (data) => {
            errorDiv.textContent = data.message;
            errorDiv.classList.add('active');
            setTimeout(() => {
                errorDiv.classList.remove('active');
            }, 5000);
        });

        function addMessage(text, role) {
            // Remove empty state if it exists
            const emptyState = chatContainer.querySelector('.empty-state');
            if (emptyState) {
                emptyState.remove();
            }

            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${role}`;
            messageDiv.textContent = text;

            chatContainer.appendChild(messageDiv);

            // Auto-scroll to bottom
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }

        async function startStreaming() {
            try {
                stream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        channelCount: 1,
                        sampleRate: 16000,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                });

                audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
                const source = audioContext.createMediaStreamSource(stream);

                const bufferSize = 4096;
                const processor = audioContext.createScriptProcessor(bufferSize, 1, 1);

                processor.onaudioprocess = (e) => {
                    if (!isRecording) return;

                    const inputData = e.inputBuffer.getChannelData(0);
                    const int16Data = new Int16Array(inputData.length);
                    for (let i = 0; i < inputData.length; i++) {
                        const s = Math.max(-1, Math.min(1, inputData[i]));
                        int16Data[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                    }

                    socket.emit('audio_chunk', {
                        audio: int16Data.buffer,
                        sampleRate: audioContext.sampleRate
                    });
                };

                source.connect(processor);
                processor.connect(audioContext.destination);

                socket.emit('start_stream');

                isRecording = true;
                micBtn.classList.add('listening');
                statusText.textContent = 'Listening...';

            } catch (err) {
                errorDiv.textContent = 'Microphone access denied';
                errorDiv.classList.add('active');
                setTimeout(() => {
                    errorDiv.classList.remove('active');
                }, 5000);
            }
        }

        function stopStreaming() {
            if (isRecording) {
                isRecording = false;

                if (audioContext) {
                    audioContext.close();
                    audioContext = null;
                }

                if (stream) {
                    stream.getTracks().forEach(track => track.stop());
                    stream = null;
                }

                socket.emit('stop_stream');

                micBtn.classList.remove('listening');
                statusText.textContent = 'Ready';
            }
        }

        micBtn.addEventListener('click', () => {
            if (isRecording) {
                stopStreaming();
            } else {
                startStreaming();
            }
        });

        // GitHub button click handler - shows toast
        githubBtn.addEventListener('click', () => {
            toast.classList.add('show');
            setTimeout(() => {
                toast.classList.remove('show');
            }, 2000);
        });

        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
            micBtn.disabled = true;
            statusText.textContent = 'Microphone not supported';
        }

        // No VAD toggle
    </script>
</body>
</html>
