<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Chat</title>
    <script src="https://cdn.socket.io/4.5.4/socket.io.min.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: #f5f5f5;
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 20px;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
            max-width: 800px;
            width: 100%;
            height: 85vh;
            display: flex;
            flex-direction: column;
        }

        .header {
            padding: 20px;
            border-bottom: 1px solid #e0e0e0;
            text-align: center;
        }

        .header h1 {
            font-size: 24px;
            color: #333;
            margin-bottom: 10px;
        }

        .chat-container {
            flex: 1;
            overflow-y: auto;
            padding: 20px;
            display: flex;
            flex-direction: column;
            gap: 15px;
        }

        .message {
            display: flex;
            animation: slideIn 0.3s ease-out;
        }

        @keyframes slideIn {
            from {
                opacity: 0;
                transform: translateY(10px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .message.user {
            justify-content: flex-end; /* Align user messages to the right */
        }

        .message-bubble {
            max-width: 70%;
            padding: 12px 16px;
            border-radius: 18px;
            line-height: 1.5;
            word-wrap: break-word;
        }

        .message.user .message-bubble {
            background: #007aff;
            color: white;
            border-bottom-right-radius: 4px;
        }

        .message.assistant .message-bubble {
            background: #e9ecef;
            color: #333;
            border-bottom-left-radius: 4px;
        }



        .controls {
            padding: 20px;
            border-top: 1px solid #e0e0e0;
            display: flex;
            justify-content: center;
            align-items: center;
            gap: 15px;
        }

        .record-btn {
            width: 120px; /* Wider button */
            height: 48px; /* Standard height */
            border-radius: 8px; /* Slightly rounded corners */
            border: none;
            background: #007aff; /* Primary blue color */
            color: white; /* White text */
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 2px 10px rgba(0, 122, 255, 0.2); /* Blue shadow */
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .record-btn:hover {
            background: #005bb5; /* Darker blue on hover */
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 122, 255, 0.3);
        }

        .record-btn:active {
            transform: translateY(0);
            box-shadow: 0 2px 8px rgba(0, 122, 255, 0.2);
        }

        .record-btn.recording {
            background: #dc3545; /* Red for recording */
            box-shadow: 0 2px 10px rgba(220, 53, 69, 0.2); /* Red shadow */
            animation: none; /* Remove pulse animation */
        }

        .record-btn.recording:hover {
            background: #c82333;
        }

        .record-btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }



        .status-text {
            color: #666;
            font-size: 14px;
        }

        .status-text.recording {
            color: #dc3545;
            font-weight: 600;
        }

        .empty-state {
            text-align: center;
            color: #999;
            padding: 40px 20px;
        }

        .empty-state-icon {
            font-size: 48px;
            margin-bottom: 10px;
        }

        .error {
            background: #ffe0e0;
            color: #d32f2f;
            padding: 15px;
            border-radius: 8px;
            margin: 10px 20px;
            display: none;
            border: 1px solid #ffcdd2;
        }

        .error.active {
            display: block;
        }

        /* Scrollbar styling */
        .chat-container::-webkit-scrollbar {
            width: 8px;
        }

        .chat-container::-webkit-scrollbar-track {
            background: #f1f1f1;
            border-radius: 10px;
        }

        .chat-container::-webkit-scrollbar-thumb {
            background: #ccc;
            border-radius: 10px;
        }

        .chat-container::-webkit-scrollbar-thumb:hover {
            background: #999;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>LintVoice</h1>
        </div>

        <div class="error" id="error"></div>

        <div class="chat-container" id="chatContainer">
            <div class="empty-state">
                <p>Click the microphone and start talking!</p>
            </div>
        </div>

        <div class="controls">
            <button class="record-btn" id="recordBtn" title="Click to start recording" disabled>
                Start
            </button>
            <span class="status-text" id="statusText">Ready</span>
        </div>
    </div>

    <script>
        let socket;
        let audioContext;
        let stream;
        let isRecording = false;
        // VAD is fixed to Silero

        const recordBtn = document.getElementById('recordBtn');
        const chatContainer = document.getElementById('chatContainer');
        const statusText = document.getElementById('statusText');
        const errorDiv = document.getElementById('error');
        // No VAD toggle in this version

        // Audio playback queue for streaming TTS
        let audioQueue = [];
        let isPlayingAudio = false;
        let audioPlaybackContext = null;
        let currentSource = null;
        let playbackEnabled = true; // gate to ignore audio when stopped
        // Gapless scheduling state
        let nextStartTime = 0; // when the next chunk should start
        let activeSources = []; // all scheduled sources for cancel/stop

        socket = io();

        socket.on('connect', () => {
            recordBtn.disabled = false;
            statusText.textContent = 'Ready';
            // Silero is default; no mode selection needed
        });

        socket.on('disconnect', () => {
            recordBtn.disabled = true;
            statusText.textContent = 'Disconnected';
            // Ensure any ongoing audio is stopped on disconnect
            playbackEnabled = false;
            stopAudioPlayback();
        });

        socket.on('vad_mode_changed', (data) => {
            console.log('VAD:', data.message);
        });
        socket.on('stream_started', (data) => {
            console.log('Stream started');
        });

        let currentAssistantBubble = null;
        let currentPartialBubble = null;

        // Pipeline stage logging
        socket.on('pipeline_stage', (data) => {
            console.log(`%c[${data.stage.toUpperCase()}] ${data.message}`,
                'color: #007aff; font-weight: bold');
        });

        socket.on('partial_transcription', (data) => {
            console.log('[PARTIAL TRANSCRIPTION]', data.text);
            // Show partial transcription while user is speaking
            if (data.text) {
                if (!currentPartialBubble) {
                    // Create a partial message bubble (lighter style)
                    const emptyState = chatContainer.querySelector('.empty-state');
                    if (emptyState) {
                        emptyState.remove();
                    }

                    const messageDiv = document.createElement('div');
                    messageDiv.className = 'message user';
                    messageDiv.style.opacity = '0.6';  // Make it lighter

                    const bubble = document.createElement('div');
                    bubble.className = 'message-bubble';
                    bubble.textContent = data.text;

                    messageDiv.appendChild(bubble);

                    chatContainer.appendChild(messageDiv);
                    chatContainer.scrollTop = chatContainer.scrollHeight;

                    currentPartialBubble = { div: messageDiv, bubble: bubble };
                } else {
                    // Update existing partial bubble
                    currentPartialBubble.bubble.textContent = data.text;
                    chatContainer.scrollTop = chatContainer.scrollHeight;
                }
            }
        });

        socket.on('user_message', (data) => {
            console.log('[USER MESSAGE] Displaying final transcription:', data.text);
            if (data.text) {
                // Remove partial bubble if exists
                if (currentPartialBubble) {
                    currentPartialBubble.div.remove();
                    currentPartialBubble = null;
                }
                // Add final message
                addMessage(data.text, 'user');
            }
        });

        socket.on('assistant_start', () => {
            console.log('[ASSISTANT START] Creating assistant message bubble');
            playbackEnabled = true;
            // Reset scheduling for a fresh response
            nextStartTime = 0;

            // Create empty assistant message bubble
            const emptyState = chatContainer.querySelector('.empty-state');
            if (emptyState) {
                emptyState.remove();
            }

            // Stop any ongoing audio from previous response
            stopAudioPlayback();

            const messageDiv = document.createElement('div');
            messageDiv.className = 'message assistant';

            const bubble = document.createElement('div');
            bubble.className = 'message-bubble';
            bubble.textContent = '';

            messageDiv.appendChild(bubble);

            chatContainer.appendChild(messageDiv);
            chatContainer.scrollTop = chatContainer.scrollHeight;

            currentAssistantBubble = bubble;
        });

        socket.on('assistant_token', (data) => {
            if (currentAssistantBubble && data.token) {
                // Log first few tokens
                if (currentAssistantBubble.textContent.length < 20) {
                    console.log('[ASSISTANT TOKEN] Received token:', data.token);
                }
                currentAssistantBubble.textContent += data.token;
                chatContainer.scrollTop = chatContainer.scrollHeight;
            }
        });

        // Periodic full text sync to fix any token drops
        socket.on('assistant_progress', (data) => {
            if (currentAssistantBubble && typeof data.text === 'string') {
                currentAssistantBubble.textContent = data.text;
                chatContainer.scrollTop = chatContainer.scrollHeight;
            }
        });

        socket.on('assistant_complete', (data) => {
            console.log('[ASSISTANT COMPLETE] Full response received');
            currentAssistantBubble = null;
        });

        // Handle streaming audio from TTS
        socket.on('assistant_audio', (data) => {
            console.log('[ASSISTANT AUDIO] Received audio chunk, queuing for playback');
            if (data.audio && playbackEnabled) {
                queueAudio(data.audio, data.sample_rate || 24000);
            }
        });

        // Cancel/stop assistant playback (barge-in)
        socket.on('assistant_cancel', () => {
            console.log('[ASSISTANT CANCEL] Stopping audio playback due to barge-in');
            playbackEnabled = false;
            stopAudioPlayback();
        });

        async function queueAudio(base64Audio, sampleRate) {
            // Decode base64 to ArrayBuffer
            const binaryString = atob(base64Audio);
            const bytes = new Uint8Array(binaryString.length);
            for (let i = 0; i < binaryString.length; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }

            // Add to queue
            audioQueue.push({ data: bytes.buffer, sampleRate: sampleRate });

            // Start playback if not already playing
            if (!isPlayingAudio) {
                playNextAudio();
            }
        }

        async function playNextAudio() {
            // Schedule all available chunks back-to-back for gapless playback
            if (audioQueue.length === 0) {
                isPlayingAudio = false;
                console.log('[AUDIO PLAYBACK] Queue empty, playback complete');
                return;
            }

            isPlayingAudio = true;

            // Initialize audio context if needed
            if (!audioPlaybackContext) {
                audioPlaybackContext = new (window.AudioContext || window.webkitAudioContext)();
                console.log('[AUDIO PLAYBACK] Audio context initialized');
                nextStartTime = 0; // reset scheduling baseline
            }

            try {
                // Schedule as many as are currently queued
                while (audioQueue.length > 0 && playbackEnabled) {
                    const audioData = audioQueue.shift();
                    // Decode WAV
                    const audioBuffer = await audioPlaybackContext.decodeAudioData(audioData.data);
                    console.log(`[AUDIO PLAYBACK] Decoded chunk: ${audioBuffer.duration.toFixed(2)}s`);

                    // Create and schedule source at precise time for gapless playback
                    const source = audioPlaybackContext.createBufferSource();
                    source.buffer = audioBuffer;
                    source.connect(audioPlaybackContext.destination);

                    // Compute start time: schedule after previously scheduled audio
                    const now = audioPlaybackContext.currentTime;
                    if (nextStartTime === 0 || nextStartTime < now) {
                        // Align to now with a tiny safety offset
                        nextStartTime = now + 0.02;
                    }
                    source.start(nextStartTime);
                    activeSources.push(source);
                    currentSource = source; // keep a reference to the most recent

                    // Advance next start time by duration
                    nextStartTime += audioBuffer.duration;
                }
            } catch (error) {
                console.error('[AUDIO PLAYBACK ERROR]', error);
            } finally {
                // If more audio arrives later, queueAudio() will call playNextAudio() again
                if (audioQueue.length === 0) {
                    isPlayingAudio = false;
                }
            }
        }

        function stopAudioPlayback() {
            // Stop all scheduled/playing sources
            try {
                activeSources.forEach(src => {
                    try {
                        src.stop(0);
                        src.disconnect();
                    } catch (_) {}
                });
                activeSources = [];
                if (currentSource) {
                    try { currentSource.stop(0); currentSource.disconnect(); } catch (_) {}
                    currentSource = null;
                }
            } catch (e) {
                console.warn('[AUDIO STOP WARNING]', e);
            }
            // Clear queue and reset scheduling
            audioQueue = [];
            isPlayingAudio = false;
            nextStartTime = 0;
        }

        socket.on('error', (data) => {
            errorDiv.textContent = data.message;
            errorDiv.classList.add('active');
            setTimeout(() => {
                errorDiv.classList.remove('active');
            }, 5000);
        });

        function addMessage(text, role) {
            // Remove empty state if it exists
            const emptyState = chatContainer.querySelector('.empty-state');
            if (emptyState) {
                emptyState.remove();
            }

            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${role}`;

            const bubble = document.createElement('div');
            bubble.className = 'message-bubble';
            bubble.textContent = text;

            messageDiv.appendChild(bubble);

            chatContainer.appendChild(messageDiv);

            // Auto-scroll to bottom
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }

        async function startStreaming() {
            try {
                stream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        channelCount: 1,
                        sampleRate: 16000,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                });

                audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
                const source = audioContext.createMediaStreamSource(stream);

                const bufferSize = 4096;
                const processor = audioContext.createScriptProcessor(bufferSize, 1, 1);

                processor.onaudioprocess = (e) => {
                    if (!isRecording) return;

                    const inputData = e.inputBuffer.getChannelData(0);
                    const int16Data = new Int16Array(inputData.length);
                    for (let i = 0; i < inputData.length; i++) {
                        const s = Math.max(-1, Math.min(1, inputData[i]));
                        int16Data[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                    }

                    socket.emit('audio_chunk', {
                        audio: int16Data.buffer,
                        sampleRate: audioContext.sampleRate
                    });
                };

                source.connect(processor);
                processor.connect(audioContext.destination);

                socket.emit('start_stream');

                isRecording = true;
                recordBtn.classList.add('recording');
                recordBtn.textContent = 'Stop';
                statusText.textContent = 'Listening...';
                statusText.classList.add('recording');

            } catch (err) {
                errorDiv.textContent = 'Microphone access denied';
                errorDiv.classList.add('active');
                setTimeout(() => {
                    errorDiv.classList.remove('active');
                }, 5000);
            }
        }

        function stopStreaming() {
            if (isRecording) {
                isRecording = false;

                if (audioContext) {
                    audioContext.close();
                    audioContext = null;
                }

                if (stream) {
                    stream.getTracks().forEach(track => track.stop());
                    stream = null;
                }

                socket.emit('stop_stream');

                recordBtn.classList.remove('recording');
                recordBtn.textContent = 'Start';
                statusText.textContent = 'Ready';
                statusText.classList.remove('recording');
            }
        }

        recordBtn.addEventListener('click', () => {
            if (isRecording) {
                stopStreaming();
            } else {
                startStreaming();
            }
        });

        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
            recordBtn.disabled = true;
            statusText.textContent = 'Microphone not supported';
        }

        // No VAD toggle
    </script>
</body>
</html>
